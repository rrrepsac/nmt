{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.12"
    },
    "colab": {
      "name": "translation_transformer.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rrrepsac/nmt/blob/master/translation_transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYn5-6pu9NeV",
        "outputId": "42ef54be-61ff-4b34-f846-1aeae6a2e16e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!gdown --id '1y3Qzjd89Evpiai2MCbkOuE5aMu-87aI2'\n",
        "!unzip pl-en.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1y3Qzjd89Evpiai2MCbkOuE5aMu-87aI2\n",
            "To: /content/pl-en.zip\n",
            "61.8MB [00:02, 22.7MB/s]\n",
            "Archive:  pl-en.zip\n",
            "   creating: pl-en/\n",
            "  inflating: pl-en/europarl-v7.pl-en.en  \n",
            "  inflating: pl-en/europarl-v7.pl-en.pl  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZPZ7Wd7IPJg"
      },
      "source": [
        "ds_name=''#'pl-en'"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m95-e7DK9wM3"
      },
      "source": [
        "def prepare_corpus(root_path, max_lines=-1):\n",
        "    files = []\n",
        "    timer = Timer()\n",
        "    for root, dirs, cur_files in os.walk(root_path):\n",
        "        if 'europar' in cur_files[0]:\n",
        "            files = [Path(root)/file for file in cur_files]\n",
        "            break\n",
        "    # print(files)\n",
        "    lines_number = 0\n",
        "    cn = 0\n",
        "    all = 0\n",
        "    sentences_en = []\n",
        "    sentences_pl = []\n",
        "    with open(files[0], 'r', encoding='utf-8') as f_en:\n",
        "        with open(files[1], 'r', encoding='utf-8') as f_pl:\n",
        "            while True:\n",
        "                line_en = f_en.readline()\n",
        "                line_pl = f_pl.readline()\n",
        "                if line_en == '' or line_en == '':\n",
        "                    timer.get(f'{lines_number}, {cn} {line_en} {line_pl}')\n",
        "                    break\n",
        "                line_en = line_en.strip()\n",
        "                line_pl = line_pl.strip()\n",
        "                if line_en.endswith('('):\n",
        "                    line_en = line_en[:-1]\n",
        "                if line_pl.endswith('('):\n",
        "                    line_pl = line_pl[:-1]\n",
        "                all += 1\n",
        "                if line_en == line_pl:\n",
        "                    continue\n",
        "                if len(line_en) < 10 or len(line_pl) < 10:\n",
        "                    continue\n",
        "                p = len(line_pl) / len(line_en)\n",
        "                if p < 1:\n",
        "                    p = 1/p\n",
        "                if p > 2:\n",
        "                    continue\n",
        "                    # print(all, lines_number, line_en.strip(), f'len={len(line_en.strip())}', '__', line_pl.strip(), f'len = {len(line_pl.strip())}', '<<')\n",
        "                    # cn += 1\n",
        "                sentences_en.append(line_en)\n",
        "                sentences_pl.append(line_pl)\n",
        "                lines_number += 1\n",
        "                if max_lines > 0 and lines_number > max_lines:\n",
        "                    break\n",
        "    with open('norm.en', 'w') as fn_en:\n",
        "        print(*sentences_en, sep='\\n', file=fn_en)\n",
        "    with open('norm.pl', 'w') as fn_pl:\n",
        "        print(*sentences_pl, sep='\\n', file=fn_pl)\n",
        "    return\n",
        "def sort_parallel_corpus(from_list, to_list):\n",
        "    sorted_positions = sorted(range(len(from_list)), key=lambda i: len(from_list[i]) + len(to_list[i]))\n",
        "    coinc_pos = 0\n",
        "    for i, (c,n) in enumerate(zip(sorted_positions[:-1], sorted_positions[1:])):\n",
        "        if from_list[c] == from_list[n] and to_list[c] == to_list[n]:\n",
        "            sorted_positions.pop(i - coinc_pos)\n",
        "            coinc_pos += 1\n",
        "    print('coinc: ', coinc_pos)\n",
        "\n",
        "    return [from_list[i] for i in sorted_positions], [to_list  [i] for i in sorted_positions]\n",
        "\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnnfzlGh-Auw"
      },
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import time\n",
        "from torch.utils.data import random_split\n",
        "from functools import wraps\n",
        "\n",
        "# def timing(f):\n",
        "#     @wraps(f)\n",
        "#     def wrapper(*args, **kwargs):\n",
        "#         t_beg = time.time()\n",
        "#         result = f(*args, **kwargs)\n",
        "#         t_end = time.time()\n",
        "#         print(f'{f.__name__} t = {t_end - t_beg}')\n",
        "#         return result\n",
        "#     return wrapper\n",
        "\n",
        "# class Timer:\n",
        "#     def __init__(self, message=''):\n",
        "#         self.start_time = time.time()\n",
        "#         self.last_time = self.start_time\n",
        "    \n",
        "#     def get(self, message='', update_time=True):\n",
        "#         t = time.time()\n",
        "#         print(f'{message}, dt = {t - self.last_time:4.3f}, all_time = {t - self.start_time: 5.3}', flush=True)\n",
        "#         if update_time:\n",
        "#             self.last_time = t\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfia4KwXBiRl"
      },
      "source": [
        "def my_iter(split_name='train', src='norm.pl', tgt='norm.en'):\n",
        "  src_seq = []\n",
        "  tgt_seq = []\n",
        "  with open(src, 'r') as f:\n",
        "    src_seq = f.readlines()\n",
        "  with open(tgt, 'r') as f:\n",
        "    tgt_seq = f.readlines()\n",
        "  l = len(src_seq)\n",
        "  ratios = [0.85, 0.1, 0.5]\n",
        "  borders= [0, int(ratios[0]*l), int(l*sum(ratios[:2])), l]\n",
        "  slices = {\n",
        "      'train': slice(borders[0], borders[1]),\n",
        "      'test' : slice(borders[1], borders[2]),\n",
        "      'valid': slice(borders[2], borders[3])\n",
        "  }\n",
        "  print('doing', split_name, slices[split_name])\n",
        "  for x, y in zip(src_seq[slices[split_name]], tgt_seq[slices[split_name]]):\n",
        "    yield (x, y)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pq6lllxC900F"
      },
      "source": [
        "prepare_corpus('pl-en', 100000)\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kjv_SyvBITi8",
        "outputId": "c07862c5-dd03-48f1-add6-4ad52d0c0de2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# !pip install -U spacy\n",
        "# !python -m spacy download en_core_web_sm\n",
        "# !python -m spacy download de_core_news_sm\n",
        "!pip install youtokentome"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: youtokentome in /usr/local/lib/python3.7/dist-packages (1.0.6)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from youtokentome) (7.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKUEzxWj0TPE"
      },
      "source": [
        "from torchtext.datasets import Multi30k\n",
        "\n",
        "def get_iter(split_name, SRC_LANGUAGE='de', TGT_LANGUAGE='en', from_ds=None):\n",
        "  if from_ds != 'pl-en':\n",
        "    return Multi30k(split=split_name, language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "  else:\n",
        "    return my_iter(split_name)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxDa9RLehIrN",
        "outputId": "fbdeb115-a318-4e01-b66e-a205d673cef3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import youtokentome as yttm\n",
        "train_iter = get_iter('train', from_ds='pl-en')\n",
        "for x in train_iter:\n",
        "  print(x)\n",
        "  break\n",
        "sseqs = []\n",
        "tseqs = []\n",
        "for src, tgt in train_iter:\n",
        "  sseqs.append(src)\n",
        "  tseqs.append(tgt)\n",
        "with open('src.txt', 'w') as f:\n",
        "  print(*sseqs, sep='', end='', file=f)\n",
        "with open('tgt.txt', 'w') as f:\n",
        "  print(*tseqs, sep='', end='', file=f)\n",
        "\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "doing train slice(0, 85000, None)\n",
            "(\"Action taken on Parliament's resolutions: see Minutes\\n\", 'Działania podjęte w wyniku rezolucji Parlamentu: Patrz protokól\\n')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8OqQXnFjmaj"
      },
      "source": [
        "voc_size = 10000\n",
        "src_bpe = yttm.BPE.train('src.txt', 'src.model', voc_size, 0.99)\n",
        "tgt_bpe = yttm.BPE.train('tgt.txt', 'tgt.model', voc_size, 0.99)\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4X76m5ckpYn"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugtjehDAfuag"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch\n",
        "\n",
        "# Define special symbols and indices\n",
        "PAD_IDX, UNK_IDX,  BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
        "special_symbols = ['<pad>', '<unk>', '<bos>', '<eos>']\n",
        " \n",
        "\n",
        "train_iter = get_iter('train')\n",
        "\n",
        "def my_collate_fn(batch):\n",
        "    src_batch, tgt_batch = zip(*batch)\n",
        "    src_batch = [torch.tensor(x) for x in src_bpe.encode(src_batch, bos=True, eos=True)]\n",
        "    tgt_batch = [torch.tensor(x) for x in tgt_bpe.encode(tgt_batch, bos=True, eos=True)]\n",
        "\n",
        "    # print(src_batch,'\\n', tgt_batch)\n",
        "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
        "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
        "    return src_batch, tgt_batch\n",
        "for x, y in DataLoader(train_iter, batch_size=2, collate_fn=my_collate_fn):\n",
        "  # print(x, y)\n",
        "  # print(tgt_bpe.decode(y.T[0].tolist()))\n",
        "  break\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BejtFlPcH__W"
      },
      "source": [
        "from torch import Tensor\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import Transformer\n",
        "import math\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# helper Module that adds positional encoding to the token embedding to introduce a notion of word order.\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self,\n",
        "                 emb_size: int,\n",
        "                 dropout: float,\n",
        "                 maxlen: int = 5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
        "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
        "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
        "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
        "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
        "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer('pos_embedding', pos_embedding)\n",
        "\n",
        "    def forward(self, token_embedding: Tensor):\n",
        "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
        "\n",
        "# helper Module to convert tensor of input indices into corresponding tensor of token embeddings\n",
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size: int, emb_size):\n",
        "        super(TokenEmbedding, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
        "        self.emb_size = emb_size\n",
        "\n",
        "    def forward(self, tokens: Tensor):\n",
        "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
        "\n",
        "# Seq2Seq Network \n",
        "class Seq2SeqTransformer(nn.Module):\n",
        "    def __init__(self,\n",
        "                 num_encoder_layers: int,\n",
        "                 num_decoder_layers: int,\n",
        "                 emb_size: int,\n",
        "                 nhead: int,\n",
        "                 src_vocab_size: int,\n",
        "                 tgt_vocab_size: int,\n",
        "                 dim_feedforward: int = 512,\n",
        "                 dropout: float = 0.1):\n",
        "        super(Seq2SeqTransformer, self).__init__()\n",
        "        self.transformer = Transformer(d_model=emb_size,\n",
        "                                       nhead=nhead,\n",
        "                                       num_encoder_layers=num_encoder_layers,\n",
        "                                       num_decoder_layers=num_decoder_layers,\n",
        "                                       dim_feedforward=dim_feedforward,\n",
        "                                       dropout=dropout)\n",
        "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
        "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
        "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
        "        self.positional_encoding = PositionalEncoding(\n",
        "            emb_size, dropout=dropout)\n",
        "\n",
        "    def forward(self,\n",
        "                src: Tensor,\n",
        "                trg: Tensor,\n",
        "                src_mask: Tensor,\n",
        "                tgt_mask: Tensor,\n",
        "                src_padding_mask: Tensor,\n",
        "                tgt_padding_mask: Tensor,\n",
        "                memory_key_padding_mask: Tensor):\n",
        "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
        "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
        "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None, \n",
        "                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
        "        return self.generator(outs)\n",
        "\n",
        "    def encode(self, src: Tensor, src_mask: Tensor):\n",
        "        return self.transformer.encoder(self.positional_encoding(\n",
        "                            self.src_tok_emb(src)), src_mask)\n",
        "\n",
        "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
        "        return self.transformer.decoder(self.positional_encoding(\n",
        "                          self.tgt_tok_emb(tgt)), memory,\n",
        "                          tgt_mask)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvccp5PQH__Z"
      },
      "source": [
        "def generate_square_subsequent_mask(sz):\n",
        "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
        "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "    return mask\n",
        "\n",
        "\n",
        "def create_mask(src, tgt):\n",
        "    src_seq_len = src.shape[0]\n",
        "    tgt_seq_len = tgt.shape[0]\n",
        "\n",
        "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
        "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
        "\n",
        "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
        "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
        "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuULfjYaH__d"
      },
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "SRC_VOCAB_SIZE = src_bpe.vocab_size()#len(vocab_transform[SRC_LANGUAGE])\n",
        "TGT_VOCAB_SIZE = tgt_bpe.vocab_size()#len(vocab_transform[TGT_LANGUAGE])\n",
        "EMB_SIZE = min(128, 512)\n",
        "NHEAD = 16\n",
        "FFN_HID_DIM = min(EMB_SIZE*4, 512)\n",
        "BATCH_SIZE = 128\n",
        "NUM_ENCODER_LAYERS = 3\n",
        "NUM_DECODER_LAYERS = 3\n",
        "\n",
        "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE, \n",
        "                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
        "\n",
        "for p in transformer.parameters():\n",
        "    if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)\n",
        "\n",
        "transformer = transformer.to(DEVICE)\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "\n",
        "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUAnVxbmH__i"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def train_epoch(model, optimizer):\n",
        "    model.train()\n",
        "    losses = 0\n",
        "    train_iter = get_iter('train')\n",
        "    train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, collate_fn=my_collate_fn)\n",
        "    \n",
        "    for i, (src, tgt) in enumerate(train_dataloader):\n",
        "        src = src.to(DEVICE)\n",
        "        tgt = tgt.to(DEVICE)\n",
        "\n",
        "        tgt_input = tgt[:-1, :]\n",
        "\n",
        "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "        # print(src.shape, tgt.shape)\n",
        "\n",
        "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        tgt_out = tgt[1:, :]\n",
        "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "        loss.backward()\n",
        "        if i % 20 == 0:\n",
        "          print('loss=', loss.item())\n",
        "        optimizer.step()\n",
        "        losses += loss.item()\n",
        "\n",
        "    return losses / len(train_dataloader)\n",
        "\n",
        "\n",
        "def evaluate(model):\n",
        "    model.eval()\n",
        "    losses = 0\n",
        "\n",
        "    val_iter = get_iter('valid')\n",
        "    val_dataloader = DataLoader(val_iter, batch_size=BATCH_SIZE, collate_fn=my_collate_fn)\n",
        "\n",
        "    for src, tgt in val_dataloader:\n",
        "        src = src.to(DEVICE)\n",
        "        tgt = tgt.to(DEVICE)\n",
        "\n",
        "        tgt_input = tgt[:-1, :]\n",
        "\n",
        "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "\n",
        "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
        "        \n",
        "        tgt_out = tgt[1:, :]\n",
        "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "        losses += loss.item()\n",
        "\n",
        "    return losses / len(val_dataloader)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwB9v3xxH__j"
      },
      "source": [
        "Now we have all the ingredients to train our model. Let's do it!\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8qT8dVCmYKM"
      },
      "source": [
        "for p in transformer.named_parameters():\n",
        "  break\n",
        "  # print(p[0], p[1].shape)\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3e9v82xAH__j",
        "outputId": "2fbc4944-321e-44f3-9b09-0f88717b8cf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from timeit import default_timer as timer\n",
        "NUM_EPOCHS = 18\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS+1):\n",
        "    start_time = timer()\n",
        "    train_loss = train_epoch(transformer, optimizer)\n",
        "    end_time = timer()\n",
        "    val_loss = evaluate(transformer)\n",
        "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
        "\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss= 2.9094691276550293\n",
            "loss= 2.984081268310547\n",
            "loss= 3.0194807052612305\n",
            "loss= 2.877934455871582\n",
            "loss= 2.9021739959716797\n",
            "loss= 2.857475757598877\n",
            "loss= 2.940941333770752\n",
            "loss= 2.812286615371704\n",
            "loss= 2.7882628440856934\n",
            "loss= 2.7479100227355957\n",
            "loss= 2.9721012115478516\n",
            "loss= 3.0513062477111816\n",
            "Epoch: 1, Train loss: 2.877, Val loss: 2.702, Epoch time = 38.944s\n",
            "loss= 2.697971820831299\n",
            "loss= 2.791795492172241\n",
            "loss= 2.791020393371582\n",
            "loss= 2.7003588676452637\n",
            "loss= 2.731104612350464\n",
            "loss= 2.688497304916382\n",
            "loss= 2.765437364578247\n",
            "loss= 2.641385078430176\n",
            "loss= 2.624960422515869\n",
            "loss= 2.5938894748687744\n",
            "loss= 2.8128561973571777\n",
            "loss= 2.8935546875\n",
            "Epoch: 2, Train loss: 2.701, Val loss: 2.540, Epoch time = 38.920s\n",
            "loss= 2.559875249862671\n",
            "loss= 2.663275957107544\n",
            "loss= 2.6226212978363037\n",
            "loss= 2.554858684539795\n",
            "loss= 2.5928895473480225\n",
            "loss= 2.5263795852661133\n",
            "loss= 2.6491987705230713\n",
            "loss= 2.51501727104187\n",
            "loss= 2.5163612365722656\n",
            "loss= 2.4621164798736572\n",
            "loss= 2.696453094482422\n",
            "loss= 2.766202688217163\n",
            "Epoch: 3, Train loss: 2.566, Val loss: 2.410, Epoch time = 38.588s\n",
            "loss= 2.4166066646575928\n",
            "loss= 2.54233717918396\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-0e5c7d2ae4cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-968993b3a4f0>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, optimizer)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m20\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m           \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss='\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mlosses\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    116\u001b[0m                    \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                    \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m                    eps=group['eps'])\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7r34dJLH__k"
      },
      "source": [
        "# actual function to translate input sentence into target language\n",
        "\n",
        "# function to generate output sequence using greedy algorithm \n",
        "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
        "    src = src.to(DEVICE)\n",
        "    src_mask = src_mask.to(DEVICE)\n",
        "\n",
        "    memory = model.encode(src, src_mask)\n",
        "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
        "    for i in range(max_len-1):\n",
        "        memory = memory.to(DEVICE)\n",
        "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
        "                    .type(torch.bool)).to(DEVICE)\n",
        "        out = model.decode(ys, memory, tgt_mask)\n",
        "        out = out.transpose(0, 1)\n",
        "        prob = model.generator(out[:, -1])\n",
        "        _, next_word = torch.max(prob, dim=1)\n",
        "        next_word = next_word.item()\n",
        "\n",
        "        ys = torch.cat([ys,\n",
        "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
        "        if next_word == EOS_IDX:\n",
        "            break\n",
        "    return ys\n",
        "\n",
        "def my_translate(model: torch.nn.Module, src_sentence: str):\n",
        "    model.eval()\n",
        "    # src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n",
        "\n",
        "    src = torch.tensor(src_bpe.encode([src_sentence], bos=True, eos=True)[0]).view(-1,1)\n",
        "    # print(src.shape, ' = src_shape')\n",
        "    num_tokens = src.shape[0]\n",
        "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
        "    tgt_tokens = greedy_decode(\n",
        "        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
        "    # print(tgt_tokens.shape)\n",
        "    return tgt_bpe.decode(tgt_tokens.view(-1,1).tolist())\n",
        "    #return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")\n",
        "\n",
        "\n",
        "def translate(model: torch.nn.Module, src_sentence: str):\n",
        "    model.eval()\n",
        "    src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n",
        "    num_tokens = src.shape[0]\n",
        "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
        "    tgt_tokens = greedy_decode(\n",
        "        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
        "    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")\n"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sAYhMPgL5lC",
        "outputId": "51e3d056-2baf-4992-fcc9-ad758b9ffeb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# print(translate(transformer, \"Eine Gruppe von Menschen steht vor einem Iglu .\"))\n",
        "for i, (src, tgt) in enumerate(get_iter('test', from_ds=ds_name)):\n",
        "  print(src.strip())\n",
        "  print(\" \".join(my_translate(transformer, src)))\n",
        "  print(tgt)\n",
        "  if i > 3:\n",
        "    break"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ein Mann mit einem orangefarbenen Hut, der etwas anstarrt.\n",
            "<BOS>  <UNK> ma n in a b lu e s hi r t i s si t ing on a b lu e . <EOS>\n",
            "A man in an orange hat starring at something.\n",
            "\n",
            "Ein Boston Terrier läuft über saftig-grünes Gras vor einem weißen Zaun.\n",
            "<BOS>  <UNK> y o un g g i r l in a b la ck s hi r t i s s h o ki ng a s a s a c row d in t he ba ck . <EOS>\n",
            "A Boston Terrier is running on lush green grass in front of a white fence.\n",
            "\n",
            "Ein Mädchen in einem Karateanzug bricht einen Stock mit einem Tritt.\n",
            "<BOS>  <UNK> g i r l in a b la ck s hi r t i s in a b lu e s hi r t i s s hi r t ing . <EOS>\n",
            "A girl in karate uniform breaking a stick with a front kick.\n",
            "\n",
            "Fünf Leute in Winterjacken und mit Helmen stehen im Schnee mit Schneemobilen im Hintergrund.\n",
            "<BOS> T he re i s pla y ing in a b la ck and s hi r t and s h o t and s h o t and b la ck s in t he i r t and s om e th ing . <EOS>\n",
            "Five people wearing winter jackets and helmets stand in the snow, with snowmobiles in the background.\n",
            "\n",
            "Leute Reparieren das Dach eines Hauses.\n",
            "<BOS> T he re e pe o p le are pla y ing a f o o o ki ng . <EOS>\n",
            "People are fixing the roof of a house.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wXgAh1magSW"
      },
      "source": [
        ""
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kl7CYvuH__l"
      },
      "source": [
        "References\n",
        "----------\n",
        "\n",
        "1. Attention is all you need paper.\n",
        "   https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf\n",
        "2. The annotated transformer. https://nlp.seas.harvard.edu/2018/04/03/attention.html#positional-encoding\n",
        "\n"
      ]
    }
  ]
}